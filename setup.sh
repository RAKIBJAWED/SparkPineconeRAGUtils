#!/bin/bash

echo "Setting up Apache Spark Python environment with modular structure..."

# Check if Python is installed
if ! command -v python3 &> /dev/null; then
    echo "Python3 is not installed. Please install Python3 first."
    exit 1
fi

# Check if Java is installed (required for Spark)
if ! command -v java &> /dev/null; then
    echo "Java is not installed. Installing OpenJDK 11..."
    sudo apt-get update
    sudo apt-get install -y openjdk-11-jdk
    export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
    echo "export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64" >> ~/.bashrc
fi

# Create virtual environment
echo "Creating virtual environment..."
python3 -m venv spark_env
source spark_env/bin/activate

# Install dependencies
echo "Installing PySpark, Pinecone, and other dependencies..."
pip install --upgrade pip
pip install -r requirements.txt

# Create necessary directories if they don't exist
mkdir -p logs
mkdir -p data

echo "Setup complete!"
echo ""
echo "üöÄ To get started:"
echo "1. Activate the virtual environment: source spark_env/bin/activate"
echo "2. Run the main script: python main.py --help"
echo "3. Try specific components:"
echo "   ‚Ä¢ Spark examples: python main.py --spark-basic"
echo "   ‚Ä¢ DataFrame examples: python main.py --spark-dataframes"
echo "   ‚Ä¢ Format string migration: python main.py --format-string"
echo "   ‚Ä¢ All components: python main.py --all"
echo ""
echo "üìÅ Project structure:"
echo "   ‚Ä¢ src/spark_examples/ - Spark operation examples"
echo "   ‚Ä¢ src/pinecone_integration/ - Vector database operations"
echo "   ‚Ä¢ src/migration_rules/ - Migration rule demonstrations"
echo "   ‚Ä¢ tests/ - Unit tests"
echo ""
echo "üß™ To run tests: python -m pytest tests/"