#!/usr/bin/env python3
"""
Migration Rule Database Inserter
This class handles inserting migration rules from structured folders into Pinecone database.
It dynamically loads rule configurations and associated script files.
"""

import json
import time
import hashlib
import os
from typing import Dict, Any, List, Optional
from pinecone import Pinecone


class MigrationRuleInserter:
    """Class to insert migration rules from structured folders into Pinecone."""
    
    def __init__(self, api_key: str, index_name: str = "developer-quickstart-py"):
        """
        Initialize Pinecone client with existing index.
        
        Args:
            api_key: Pinecone API key
            index_name: Name of existing Pinecone index
        """
        self.api_key = api_key
        self.index_name = index_name
        self.pc = Pinecone(api_key=api_key)
        
        # Connect to existing index
        try:
            self.index = self.pc.Index(index_name)
            print(f"üîó Connected to existing index: {index_name}")
        except Exception as e:
            print(f"‚ùå Error connecting to index {index_name}: {e}")
            self.index = None
    
    def load_script_file(self, file_path: str) -> Optional[str]:
        """
        Load Python script content from file.
        
        Args:
            file_path: Path to the Python script file
            
        Returns:
            String containing the script content or None if error
        """
        try:
            if not os.path.exists(file_path):
                print(f"‚ö†Ô∏è  Script file not found: {file_path}")
                return None
                
            with open(file_path, 'r', encoding='utf-8') as file:
                script_content = file.read()
                print(f"‚úÖ Loaded script from {file_path} ({len(script_content)} chars)")
                return script_content
        except Exception as e:
            print(f"‚ùå Error loading script file {file_path}: {e}")
            return None
    
    def load_rule_from_folder(self, rule_folder_path: str) -> Optional[Dict[str, Any]]:
        """
        Load migration rule from a structured folder containing rule_config.json and script files.
        
        Args:
            rule_folder_path: Path to the rule folder
            
        Returns:
            Dictionary containing the rule data with loaded scripts or None if error
        """
        try:
            config_file = os.path.join(rule_folder_path, 'rule_config.json')
            
            if not os.path.exists(config_file):
                print(f"‚ùå Rule config file not found: {config_file}")
                return None
            
            # Load rule configuration
            with open(config_file, 'r', encoding='utf-8') as file:
                rule_data = json.load(file)
                print(f"üìã Loaded rule config: {rule_data.get('rule_name', 'Unknown Rule')}")
            
            # Load before script from standard location
            before_script_path = os.path.join(rule_folder_path, 'before_script.py')
            if os.path.exists(before_script_path):
                before_script = self.load_script_file(before_script_path)
                if before_script:
                    rule_data['before_script'] = before_script
                    print(f"‚úÖ Loaded before script ({len(before_script)} chars)")
                else:
                    print(f"‚ö†Ô∏è  Failed to load before script from {before_script_path}")
            else:
                print(f"‚ö†Ô∏è  Before script not found at {before_script_path}")
            
            # Load after script from standard location
            after_script_path = os.path.join(rule_folder_path, 'after_script.py')
            if os.path.exists(after_script_path):
                after_script = self.load_script_file(after_script_path)
                if after_script:
                    rule_data['after_script'] = after_script
                    print(f"‚úÖ Loaded after script ({len(after_script)} chars)")
                else:
                    print(f"‚ö†Ô∏è  Failed to load after script from {after_script_path}")
            else:
                print(f"‚ö†Ô∏è  After script not found at {after_script_path}")
            
            return rule_data
            
        except FileNotFoundError:
            print(f"‚ùå Rule folder not found: {rule_folder_path}")
            return None
        except json.JSONDecodeError as e:
            print(f"‚ùå Error parsing rule config JSON: {e}")
            return None
        except Exception as e:
            print(f"‚ùå Unexpected error loading rule from folder: {e}")
            return None
    
    def generate_embedding(self, text: str, dimension: int = 1024) -> List[float]:
        """
        Generate a hash-based embedding for the rule text.
        In production, use a proper embedding model like OpenAI, Sentence Transformers, etc.
        
        Args:
            text: Text to embed
            dimension: Embedding dimension
            
        Returns:
            List of float values representing the embedding
        """
        # Create a hash of the text
        hash_obj = hashlib.md5(text.encode())
        hash_hex = hash_obj.hexdigest()
        
        # Convert hash to numbers and normalize
        embedding = []
        for i in range(0, len(hash_hex), 2):
            # Take pairs of hex digits and convert to float
            hex_pair = hash_hex[i:i+2]
            value = int(hex_pair, 16) / 255.0  # Normalize to 0-1
            embedding.append(value)
        
        # Extend or truncate to desired dimension
        while len(embedding) < dimension:
            embedding.extend(embedding[:min(len(embedding), dimension - len(embedding))])
        
        return embedding[:dimension]
    
    def create_vector_from_rule(self, rule_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Convert rule data to Pinecone vector format.
        
        Args:
            rule_data: Dictionary containing the migration rule data
            
        Returns:
            Vector dictionary ready for Pinecone insertion
        """
        # Create combined text for embedding
        combined_text = f"""
        Rule: {rule_data.get('spark_rule', '')}
        Migration: {rule_data.get('rule_name', '')}
        Language: {rule_data.get('language', '')}
        Source Version: {rule_data.get('source_spark_version', '')}
        Target Version: {rule_data.get('target_spark_version', '')}
        Before Script: {rule_data.get('before_script', '')[:500]}
        After Script: {rule_data.get('after_script', '')[:500]}
        Error: {rule_data.get('error_with_before_script', '')}
        Category: {rule_data.get('category', '')}
        Tags: {' '.join(rule_data.get('tags', []))}
        """.strip()
        
        # Generate embedding
        embedding = self.generate_embedding(combined_text)
        
        # Create vector with metadata
        vector = {
            "id": rule_data.get('rule_id', f"rule_{int(time.time())}"),
            "values": embedding,
            "metadata": {
                "rule_name": rule_data.get('rule_name', ''),
                "language": rule_data.get('language', 'python'),
                "before_script": rule_data.get('before_script', ''),
                "after_script": rule_data.get('after_script', ''),
                "error_with_before_script": rule_data.get('error_with_before_script', ''),
                "source_spark_version": rule_data.get('source_spark_version', ''),
                "target_spark_version": rule_data.get('target_spark_version', ''),
                "spark_rule": rule_data.get('spark_rule', ''),
                "spark_doc_link": rule_data.get('spark_doc_link', ''),
                "migration_type": rule_data.get('migration_type', ''),
                "severity": rule_data.get('severity', 'medium'),
                "category": rule_data.get('category', ''),
                "tags": rule_data.get('tags', []),
                "created_at": rule_data.get('created_at', time.time())
            }
        }
        
        return vector
    
    def test_migration_scripts(self, rule_data: Dict[str, Any]) -> bool:
        """
        Test both before and after scripts to ensure they are valid Python code.
        
        Args:
            rule_data: Dictionary containing the migration rule data
            
        Returns:
            bool: True if both scripts are valid Python code
        """
        try:
            print("\nüß™ Testing migration scripts...")
            
            # Test before script
            before_script = rule_data.get('before_script', '')
            if before_script:
                try:
                    compile(before_script, '<before_script>', 'exec')
                    print("‚úÖ Before script: Valid Python syntax")
                except SyntaxError as e:
                    print(f"‚ùå Before script: Syntax error - {e}")
                    return False
            else:
                print("‚ö†Ô∏è  No before script found")
            
            # Test after script
            after_script = rule_data.get('after_script', '')
            if after_script:
                try:
                    compile(after_script, '<after_script>', 'exec')
                    print("‚úÖ After script: Valid Python syntax")
                except SyntaxError as e:
                    print(f"‚ùå After script: Syntax error - {e}")
                    return False
            else:
                print("‚ö†Ô∏è  No after script found")
            
            print("‚úÖ All scripts passed syntax validation")
            return True
            
        except Exception as e:
            print(f"‚ùå Error testing scripts: {e}")
            return False
    
    def insert_rule_from_folder(self, rule_folder_path: str, test_scripts: bool = True) -> bool:
        """
        Load rule from folder and insert into Pinecone index.
        
        Args:
            rule_folder_path: Path to the rule folder
            test_scripts: Whether to test script syntax before insertion
            
        Returns:
            bool: True if successful
        """
        try:
            if not self.index:
                print("‚ùå Index not available. Please check connection.")
                return False
            
            print(f"\nüìÅ Processing rule folder: {rule_folder_path}")
            
            # Load rule from folder (with dynamic script loading)
            rule_data = self.load_rule_from_folder(rule_folder_path)
            if not rule_data:
                return False
            
            # Test scripts if requested
            if test_scripts:
                if not self.test_migration_scripts(rule_data):
                    print("‚ùå Script validation failed. Aborting insertion.")
                    return False
            
            # Create vector from rule data
            vector = self.create_vector_from_rule(rule_data)
            
            print(f"\nüìù Inserting migration rule: {rule_data.get('rule_name', 'Unknown Rule')}")
            print(f"   üÜî Rule ID: {vector['id']}")
            print(f"   üíª Language: {rule_data.get('language', 'python')}")
            print(f"   üìä Versions: {rule_data.get('source_spark_version', 'N/A')} ‚Üí {rule_data.get('target_spark_version', 'N/A')}")
            print(f"   üè∑Ô∏è  Category: {rule_data.get('category', 'N/A')} | Severity: {rule_data.get('severity', 'N/A')}")
            print(f"   üè∑Ô∏è  Tags: {', '.join(rule_data.get('tags', []))}")
            
            # Show script information
            before_script_len = len(rule_data.get('before_script', ''))
            after_script_len = len(rule_data.get('after_script', ''))
            print(f"   üìÑ Before script: {before_script_len} characters")
            print(f"   üìÑ After script: {after_script_len} characters")
            
            # Insert vector into Pinecone
            response = self.index.upsert(vectors=[vector])
            
            if response.get('upserted_count', 0) > 0:
                print(f"‚úÖ Successfully inserted rule into index '{self.index_name}'!")
                print(f"   üìà Upserted count: {response['upserted_count']}")
                return True
            else:
                print("‚ùå Failed to insert rule - no vectors were upserted")
                return False
                
        except Exception as e:
            print(f"‚ùå Error inserting rule from folder: {e}")
            return False
    
    def insert_all_rules_from_directory(self, rules_directory: str, test_scripts: bool = True) -> Dict[str, bool]:
        """
        Insert all migration rules from a directory containing rule folders.
        
        Args:
            rules_directory: Path to directory containing rule folders
            test_scripts: Whether to test script syntax before insertion
            
        Returns:
            Dictionary mapping rule folder names to insertion success status
        """
        results = {}
        
        try:
            if not os.path.exists(rules_directory):
                print(f"‚ùå Rules directory not found: {rules_directory}")
                return results
            
            print(f"\nüìÇ Scanning rules directory: {rules_directory}")
            
            # Get all subdirectories (rule folders)
            rule_folders = [f for f in os.listdir(rules_directory) 
                          if os.path.isdir(os.path.join(rules_directory, f))]
            
            if not rule_folders:
                print("‚ö†Ô∏è  No rule folders found in directory")
                return results
            
            print(f"üìã Found {len(rule_folders)} rule folders: {', '.join(rule_folders)}")
            
            # Process each rule folder
            for rule_folder in rule_folders:
                rule_folder_path = os.path.join(rules_directory, rule_folder)
                print(f"\n{'='*60}")
                print(f"Processing rule: {rule_folder}")
                print(f"{'='*60}")
                
                success = self.insert_rule_from_folder(rule_folder_path, test_scripts)
                results[rule_folder] = success
                
                if success:
                    print(f"‚úÖ {rule_folder}: Successfully inserted")
                else:
                    print(f"‚ùå {rule_folder}: Failed to insert")
                
                # Small delay between insertions
                time.sleep(1)
            
            # Summary
            successful = sum(1 for success in results.values() if success)
            total = len(results)
            
            print(f"\n{'='*60}")
            print(f"üìä INSERTION SUMMARY")
            print(f"{'='*60}")
            print(f"‚úÖ Successful: {successful}/{total}")
            print(f"‚ùå Failed: {total - successful}/{total}")
            
            if successful > 0:
                print(f"üéâ Successfully inserted {successful} migration rules!")
            
            return results
            
        except Exception as e:
            print(f"‚ùå Error processing rules directory: {e}")
            return results
    
    def search_migration_rules_by_language(self, query: str, language: str, top_k: int = 5) -> Optional[List[Dict[str, Any]]]:
        """
        Search for migration rules based on query and filter by language.
        
        Args:
            query: Search query
            language: Programming language filter (python, scala, java)
            top_k: Number of results to return
            
        Returns:
            List of relevant migration rules for the specified language
        """
        try:
            if not self.index:
                print("‚ùå Index not available. Please check connection.")
                return None
            
            # Validate language parameter
            valid_languages = ['python', 'scala', 'java']
            if language.lower() not in valid_languages:
                print(f"‚ùå Invalid language '{language}'. Valid options: {', '.join(valid_languages)}")
                return None
            
            # Generate embedding for query
            query_embedding = self.generate_embedding(query)
            
            print(f"üîç Searching for {language} rules related to: '{query}'")
            response = self.index.query(
                vector=query_embedding,
                top_k=top_k * 3,  # Get more results to filter by language
                include_metadata=True,
                filter={"language": {"$eq": language.lower()}}
            )
            
            results = []
            print(f"\nüìã Found {len(response['matches'])} relevant {language} migration rules:")
            
            for i, match in enumerate(response['matches'][:top_k]):  # Limit to top_k after filtering
                metadata = match['metadata']
                result = {
                    "id": match['id'],
                    "score": match['score'],
                    "rule_name": metadata.get('rule_name', ''),
                    "language": metadata.get('language', 'python'),
                    "spark_rule": metadata.get('spark_rule', ''),
                    "source_version": metadata.get('source_spark_version', ''),
                    "target_version": metadata.get('target_spark_version', ''),
                    "category": metadata.get('category', ''),
                    "severity": metadata.get('severity', ''),
                    "tags": metadata.get('tags', []),
                    "documentation": metadata.get('spark_doc_link', '')
                }
                results.append(result)
                
                print(f"\n{i+1}. üìù {metadata.get('rule_name', 'Unknown Rule')} (Score: {match['score']:.4f})")
                print(f"   üíª Language: {metadata.get('language', 'python')}")
                print(f"   üè∑Ô∏è  Category: {metadata.get('category', 'N/A')} | Severity: {metadata.get('severity', 'N/A')}")
                print(f"   üìä Versions: {metadata.get('source_spark_version', '')} ‚Üí {metadata.get('target_spark_version', '')}")
                print(f"   üè∑Ô∏è  Tags: {', '.join(metadata.get('tags', []))}")
                print(f"   üìÑ Scripts: Available in metadata")
                print(f"   üìñ Documentation: {metadata.get('spark_doc_link', 'N/A')}")
            
            return results
            
        except Exception as e:
            print(f"‚ùå Error searching for {language} rules: {e}")
            return None

    def search_migration_rules(self, query: str, top_k: int = 5) -> Optional[List[Dict[str, Any]]]:
        """
        Search for migration rules based on query.
        
        Args:
            query: Search query
            top_k: Number of results to return
            
        Returns:
            List of relevant migration rules
        """
        try:
            if not self.index:
                print("‚ùå Index not available. Please check connection.")
                return None
            
            # Generate embedding for query
            query_embedding = self.generate_embedding(query)
            
            print(f"üîç Searching for rules related to: '{query}'")
            response = self.index.query(
                vector=query_embedding,
                top_k=top_k,
                include_metadata=True
            )
            
            results = []
            print(f"\nüìã Found {len(response['matches'])} relevant migration rules:")
            
            for i, match in enumerate(response['matches']):
                metadata = match['metadata']
                result = {
                    "id": match['id'],
                    "score": match['score'],
                    "rule_name": metadata.get('rule_name', ''),
                    "language": metadata.get('language', 'python'),
                    "spark_rule": metadata.get('spark_rule', ''),
                    "source_version": metadata.get('source_spark_version', ''),
                    "target_version": metadata.get('target_spark_version', ''),
                    "category": metadata.get('category', ''),
                    "severity": metadata.get('severity', ''),
                    "tags": metadata.get('tags', []),
                    "documentation": metadata.get('spark_doc_link', '')
                }
                results.append(result)
                
                print(f"\n{i+1}. üìù {metadata.get('rule_name', 'Unknown Rule')} (Score: {match['score']:.4f})")
                print(f"   üíª Language: {metadata.get('language', 'python')}")
                print(f"   üè∑Ô∏è  Category: {metadata.get('category', 'N/A')} | Severity: {metadata.get('severity', 'N/A')}")
                print(f"   üìä Versions: {metadata.get('source_spark_version', '')} ‚Üí {metadata.get('target_spark_version', '')}")
                print(f"   üè∑Ô∏è  Tags: {', '.join(metadata.get('tags', []))}")
                print(f"   üìÑ Scripts: Available in metadata")
                print(f"   üìñ Documentation: {metadata.get('spark_doc_link', 'N/A')}")
            
            return results
            
        except Exception as e:
            print(f"‚ùå Error searching for rules: {e}")
            return None
    
    def get_language_statistics(self) -> Optional[Dict[str, int]]:
        """
        Get statistics about migration rules by language.
        
        Returns:
            Dictionary with language counts
        """
        try:
            if not self.index:
                print("‚ùå Index not available. Please check connection.")
                return None
            
            print("\nüìä Migration Rules by Language:")
            
            language_stats = {}
            valid_languages = ['python', 'scala', 'java']
            
            for language in valid_languages:
                try:
                    # Query for each language with a dummy vector (we just want the count)
                    dummy_embedding = self.generate_embedding("dummy")
                    response = self.index.query(
                        vector=dummy_embedding,
                        top_k=1000,  # Large number to get all results
                        include_metadata=False,
                        filter={"language": {"$eq": language}}
                    )
                    count = len(response['matches'])
                    language_stats[language] = count
                    print(f"   üíª {language.capitalize()}: {count} rules")
                except Exception as e:
                    print(f"   ‚ùå Error getting {language} count: {e}")
                    language_stats[language] = 0
            
            total = sum(language_stats.values())
            print(f"   üìà Total: {total} rules")
            
            return language_stats
            
        except Exception as e:
            print(f"‚ùå Error getting language statistics: {e}")
            return None

    def get_index_stats(self) -> Optional[Dict[str, Any]]:
        """
        Get statistics about the migration rules in the index.
        
        Returns:
            Index statistics
        """
        try:
            if not self.index:
                print("‚ùå Index not available. Please check connection.")
                return None
            
            stats = self.index.describe_index_stats()
            print("\nüìä Migration Rules Database Statistics:")
            print(f"   üìà Total rules: {stats.get('total_vector_count', 0)}")
            print(f"   üìè Vector dimension: {stats.get('dimension', 0)}")
            if 'namespaces' in stats:
                print(f"   üè∑Ô∏è  Namespaces: {list(stats['namespaces'].keys())}")
            
            return stats
            
        except Exception as e:
            print(f"‚ùå Error getting index stats: {e}")
            return None


def main():
    """Main function to demonstrate migration rule insertion from structured folders."""
    # Initialize with your API key
    api_key = "pcsk_4kn9f1_7pTT2RoGerBQkmCKTMgUsR6BzKXvYwrYmLCdM3dEZCu58LRtmMz9yoJ4NgWpDjv"
    
    print("üöÄ Migration Rule Database Inserter")
    print("="*50)
    
    # Create inserter instance
    inserter = MigrationRuleInserter(api_key, "developer-quickstart-py")
    
    try:
        # 1. Insert single rule from folder
        print("\n1Ô∏è‚É£  Inserting Format String Migration Rule...")
        rule_folder = "src/migration_rules/format_string_rule"
        
        if inserter.insert_rule_from_folder(rule_folder):
            print("‚úÖ Single rule insertion completed!")
        else:
            print("‚ùå Single rule insertion failed!")
        
        # Wait for indexing
        time.sleep(2)
        
        # 2. Get Index Stats
        print("\n2Ô∏è‚É£  Getting Database Statistics...")
        inserter.get_index_stats()
        
        # 2b. Get Language Statistics
        print("\n2Ô∏è‚É£b Getting Language Statistics...")
        inserter.get_language_statistics()
        
        # 3. Search for format string rules
        print("\n3Ô∏è‚É£  Searching for Format String Rules...")
        inserter.search_migration_rules("format_string printf argument index")
        
        # 3b. Search for Python-specific rules
        print("\n3Ô∏è‚É£b Searching for Python-specific Rules...")
        inserter.search_migration_rules_by_language("format_string", "python")
        
        # 4. Insert all rules from directory (if there are more)
        print("\n4Ô∏è‚É£  Scanning for additional rules...")
        rules_directory = "src/migration_rules"
        results = inserter.insert_all_rules_from_directory(rules_directory, test_scripts=True)
        
        print(f"\nüìã Insertion results: {results}")
        
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è  Operation interrupted by user.")
    except Exception as e:
        print(f"‚ùå Unexpected error: {e}")
    
    print("\nüèÅ Migration Rule Insertion Process Complete!")


if __name__ == "__main__":
    main()