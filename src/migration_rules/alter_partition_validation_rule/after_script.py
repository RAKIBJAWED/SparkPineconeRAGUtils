#!/usr/bin/env python3
"""
ALTER PARTITION Type Validation Migration - AFTER Script (Spark 3.4+)
This script demonstrates the updated behavior with strict type validation.

Language: Python
Usage: python after_script.py

This script can be run independently to test the updated behavior.
In Spark 3.4+, ALTER PARTITION validates partition spec types against column types.
"""

from pyspark.sql import SparkSession
from pyspark.sql.types import StructType, StructField, IntegerType, StringType
import tempfile
import shutil
import os


def main():
    # Create SparkSession with Spark 3.4+ behavior (strict validation)
    spark = SparkSession.builder \
        .appName('AlterPartitionValidationAfter') \
        .master('local[*]') \
        .config('spark.sql.legacy.skipTypeValidationOnAlterPartition', 'false') \
        .config('spark.sql.warehouse.dir', 'spark-warehouse') \
        .getOrCreate()
    
    print("=== ALTER PARTITION Type Validation - AFTER (Spark 3.4+ behavior) ===")
    print("Configuration: spark.sql.legacy.skipTypeValidationOnAlterPartition = false")
    
    # Create a temporary directory for our table
    temp_dir = tempfile.mkdtemp()
    table_path = os.path.join(temp_dir, "test_partition_table")
    
    try:
        # Create sample data with integer partition column
        print("\nüìä Creating sample partitioned table...")
        
        # Define schema with integer partition column
        schema = StructType([
            StructField("id", IntegerType(), True),
            StructField("name", StringType(), True),
            StructField("partition_col", IntegerType(), True)  # Integer partition column
        ])
        
        # Create sample data
        data = [
            (1, "Alice", 100),
            (2, "Bob", 200),
            (3, "Charlie", 100),
            (4, "David", 200)
        ]
        
        df = spark.createDataFrame(data, schema)
        
        # Write as partitioned table
        df.write \
          .mode("overwrite") \
          .partitionBy("partition_col") \
          .option("path", table_path) \
          .saveAsTable("test_partition_table")
        
        print("‚úÖ Created partitioned table with integer partition column 'partition_col'")
        
        # Show current partitions
        print("\nüìã Current partitions:")
        spark.sql("SHOW PARTITIONS test_partition_table").show()
        
        # Demonstrate the NEW behavior - type validation prevents mismatches
        print("\nüîç ATTEMPTING: ALTER TABLE ADD PARTITION with string value for int column...")
        print("   SQL: ALTER TABLE test_partition_table ADD PARTITION (partition_col='300')")
        
        try:
            # This will fail in Spark 3.4+ due to type validation
            spark.sql("ALTER TABLE test_partition_table ADD PARTITION (partition_col='300')")
            print("‚ùå UNEXPECTED: Partition was added (this shouldn't happen in Spark 3.4+)")
            
        except Exception as e:
            print(f"‚úÖ EXPECTED FAILURE: {e}")
            print("   üéâ Type validation prevented the type mismatch!")
            print("   üí° This protects data integrity")
        
        # Demonstrate the CORRECT way - using proper types
        print(f"\n‚úÖ CORRECT APPROACH: Adding partition with proper integer value...")
        print("   SQL: ALTER TABLE test_partition_table ADD PARTITION (partition_col=300)")
        
        try:
            spark.sql("ALTER TABLE test_partition_table ADD PARTITION (partition_col=300)")
            print("‚úÖ SUCCESS: Partition added with correct integer value")
            
            # Show updated partitions
            print("\nüìã Partitions after adding correct partition:")
            spark.sql("SHOW PARTITIONS test_partition_table").show()
            
        except Exception as e:
            print(f"‚ùå Unexpected error with correct type: {e}")
        
        # Demonstrate another type validation scenario
        print(f"\nüîç ATTEMPTING: Adding partition with completely invalid string...")
        print("   SQL: ALTER TABLE test_partition_table ADD PARTITION (partition_col='invalid_string')")
        
        try:
            spark.sql("ALTER TABLE test_partition_table ADD PARTITION (partition_col='invalid_string')")
            print("‚ùå UNEXPECTED: Invalid partition was added")
            
        except Exception as e:
            print(f"‚úÖ EXPECTED FAILURE: {e}")
            print("   üéâ Type validation prevented invalid data!")
        
        # Show how to handle convertible strings
        print(f"\nüí° BEST PRACTICE: Using convertible string values...")
        print("   SQL: ALTER TABLE test_partition_table ADD PARTITION (partition_col=400)")
        
        try:
            # Use integer literal instead of string
            spark.sql("ALTER TABLE test_partition_table ADD PARTITION (partition_col=400)")
            print("‚úÖ SUCCESS: Partition added with integer literal")
            
        except Exception as e:
            print(f"‚ùå Error: {e}")
        
        # Demonstrate programmatic approach for dynamic partition addition
        print(f"\nüîß PROGRAMMATIC APPROACH: Adding partitions with proper type casting...")
        
        try:
            # When adding partitions programmatically, ensure proper types
            partition_value = 500  # Integer value
            spark.sql(f"ALTER TABLE test_partition_table ADD PARTITION (partition_col={partition_value})")
            print(f"‚úÖ SUCCESS: Added partition with value {partition_value}")
            
        except Exception as e:
            print(f"‚ùå Error: {e}")
        
        # Final partition list
        print(f"\nüìä Final partition list:")
        spark.sql("SHOW PARTITIONS test_partition_table").show()
        
        # Query all data to verify integrity
        print(f"\nüîç Querying all data to verify integrity:")
        result = spark.sql("SELECT * FROM test_partition_table ORDER BY id")
        result.show()
        
        print(f"\nüéØ MIGRATION RECOMMENDATIONS:")
        print(f"   ‚úÖ Always use correct data types in partition specs")
        print(f"   ‚úÖ Validate partition values before ALTER PARTITION commands")
        print(f"   ‚úÖ Use integer literals for integer partition columns")
        print(f"   ‚úÖ Test partition operations in development environment")
        print(f"   ‚ö†Ô∏è  If legacy behavior is absolutely needed, set:")
        print(f"      spark.sql.legacy.skipTypeValidationOnAlterPartition=true")
        
    except Exception as e:
        print(f"‚ùå Error during demonstration: {e}")
        print("   Check your Spark configuration and table setup")
    
    finally:
        # Cleanup
        try:
            spark.sql("DROP TABLE IF EXISTS test_partition_table")
            if os.path.exists(temp_dir):
                shutil.rmtree(temp_dir)
        except:
            pass
        
        spark.stop()
        print("\nSpark session stopped.")
        
        print(f"\nüéâ SUMMARY - Spark 3.4+ Benefits:")
        print(f"   ‚Ä¢ Strict type validation prevents data integrity issues")
        print(f"   ‚Ä¢ Early error detection for type mismatches")
        print(f"   ‚Ä¢ Consistent behavior with spark.sql.storeAssignmentPolicy")
        print(f"   ‚Ä¢ Better data quality and reliability")


if __name__ == "__main__":
    main()