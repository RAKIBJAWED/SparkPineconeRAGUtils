// Cast Auto-Generation Column Alias Migration - BEFORE Script (Spark 3.1 and earlier)
// This script demonstrates the old behavior where auto-generated CAST expressions appeared in column names.
//
// Language: Scala
// Usage: spark-shell -i before_script.scala
//
// This script can be run independently to test the old behavior.

import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions._
import org.apache.spark.sql.types._

object CastAliasMigrationBefore {
  def main(args: Array[String]): Unit = {
    // Create SparkSession
    val spark = SparkSession.builder()
      .appName("CastAliasMigrationBefore")
      .master("local[*]")
      .config("spark.sql.warehouse.dir", "spark-warehouse")
      .getOrCreate()

    import spark.implicits._

    println("=== Cast Auto-Generation Column Alias Migration - BEFORE (Spark 3.1 behavior) ===")

    try {
      // Create sample data
      println("\nğŸ“Š Creating sample data...")
      val data = Seq(
        (1, 2.5, "2021-01-01"),
        (2, 3.7, "2021-02-15"),
        (3, 1.2, "2021-03-30")
      ).toDF("id", "value", "date_str")

      data.show()
      println("Schema:")
      data.printSchema()

      // Demonstrate FLOOR function with implicit casting
      println("\nâš ï¸  DEMONSTRATING: FLOOR function with implicit type coercion...")
      println("   SQL: SELECT floor(1) AS floor_result")

      try {
        val floorResult = spark.sql("SELECT floor(1) AS floor_result")
        println("âœ… Query executed successfully")
        floorResult.show()

        // Check column names - this is where the issue appears
        val columnNames = floorResult.columns
        println(s"ğŸ“‹ Column names: ${columnNames.mkString(", ")}")

        // In Spark 3.1, this might show something like "FLOOR(CAST(1 AS DOUBLE))"
        println("âš ï¸  ISSUE: Column name may include auto-generated CAST expression")

      } catch {
        case e: Exception =>
          println(s"âŒ Error: ${e.getMessage}")
      }

      // Demonstrate with DataFrame API
      println("\nâš ï¸  DEMONSTRATING: DataFrame API with implicit casting...")
      try {
        val dfResult = data.select(
          col("id"),
          floor(lit(1)).alias("floor_literal"),
          floor(col("value")).alias("floor_value"),
          ceil(col("value")).alias("ceil_value")
        )

        println("âœ… DataFrame operations executed")
        dfResult.show()

        println("ğŸ“‹ Column names from DataFrame API:")
        dfResult.columns.foreach(colName => println(s"   â€¢ $colName"))

      } catch {
        case e: Exception =>
          println(s"âŒ Error: ${e.getMessage}")
      }

      // Demonstrate more complex expressions with type coercion
      println("\nâš ï¸  DEMONSTRATING: Complex expressions with type coercion...")
      try {
        val complexResult = spark.sql("""
          SELECT 
            floor(1) as floor_int,
            floor(1.5) as floor_double,
            ceil(2) as ceil_int,
            round(3) as round_int,
            abs(-4) as abs_int,
            sqrt(9) as sqrt_int
        """)

        println("âœ… Complex expressions executed")
        complexResult.show()

        println("ğŸ“‹ Column names with potential CAST expressions:")
        complexResult.columns.foreach { colName =>
          println(s"   â€¢ $colName")
          if (colName.contains("CAST")) {
            println(s"     âš ï¸  Contains CAST expression!")
          }
        }

      } catch {
        case e: Exception =>
          println(s"âŒ Error: ${e.getMessage}")
      }

      // Demonstrate the impact on downstream operations
      println("\nâš ï¸  DEMONSTRATING: Impact on downstream operations...")
      try {
        // Create a view with potentially problematic column names
        val viewResult = spark.sql("SELECT floor(1) as computed_floor")
        viewResult.createOrReplaceTempView("temp_view")

        // Try to reference the column in another query
        println("   Attempting to reference column in subsequent query...")
        val referenceResult = spark.sql("SELECT computed_floor * 2 FROM temp_view")
        referenceResult.show()

        println("âœ… Reference worked, but column name consistency may be an issue")

      } catch {
        case e: Exception =>
          println(s"âŒ Error referencing column: ${e.getMessage}")
          println("   This demonstrates potential downstream issues")
      }

      // Show column name extraction for programmatic use
      println("\nâš ï¸  DEMONSTRATING: Programmatic column name usage...")
      try {
        val testDF = spark.sql("SELECT floor(1), ceil(2.5), round(3.7)")
        val columns = testDF.columns

        println("ğŸ“‹ Extracted column names for programmatic use:")
        columns.zipWithIndex.foreach { case (colName, index) =>
          println(s"   Column $index: '$colName'")
          
          // This is where problems occur - column names might be inconsistent
          if (colName.length > 20) {
            println(s"     âš ï¸  Very long column name - likely contains CAST expression")
          }
        }

        // Demonstrate potential issues with column selection
        println("\n   Attempting to select columns programmatically...")
        val selectedDF = testDF.select(columns.head)
        selectedDF.show()

      } catch {
        case e: Exception =>
          println(s"âŒ Error with programmatic column usage: ${e.getMessage}")
      }

      println("\nâš ï¸  LEGACY BEHAVIOR ISSUES:")
      println("   â€¢ Column names include verbose CAST expressions")
      println("   â€¢ Inconsistent naming between similar operations")
      println("   â€¢ Harder to reference columns programmatically")
      println("   â€¢ Potential issues with external tools expecting clean names")
      println("   â€¢ Reduced readability in query results")

    } catch {
      case e: Exception =>
        println(s"âŒ Error during demonstration: ${e.getMessage}")
        println("   This demonstrates potential issues with auto-generated column names")
    } finally {
      spark.stop()
      println("\nSpark session stopped.")

      println("\nğŸ¯ SUMMARY - Spark 3.1 and Earlier Behavior:")
      println("   â€¢ Auto-generated CAST expressions appeared in column aliases")
      println("   â€¢ Column names could be verbose and inconsistent")
      println("   â€¢ Made programmatic column handling more difficult")
      println("   â€¢ Reduced query result readability")
    }
  }
}

// If running in spark-shell, call the main method
CastAliasMigrationBefore.main(Array())